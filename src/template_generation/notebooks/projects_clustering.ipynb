{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884b1612-fb04-46f4-8f95-9061c3358b7d",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839f7362",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-30T10:07:35.995613Z"
    },
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "category = 'py'\n",
    "df = load_dataset('JetBrains-Research/template-generation', category, split='dev')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b791978e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:21:57.026186Z",
     "start_time": "2024-05-28T13:21:57.021729Z"
    },
    "is_executing": true
   },
   "source": [
    "import ast\n",
    "\n",
    "df = df.map(lambda example: {'topics': ast.literal_eval(example['topics'])}, batched=False)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "edb95a03-edb6-42db-a4f7-6a0717b824fc",
   "metadata": {},
   "source": [
    "## Select only 'fastapi', 'django', 'flask' exaples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7520bfff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:21:57.033183Z",
     "start_time": "2024-05-28T13:21:57.026898Z"
    }
   },
   "source": [
    "topics_to_check = ['fastapi', 'flask']\n",
    "\n",
    "\n",
    "def classify_by_topic(dp):\n",
    "    class_topic = None\n",
    "    \n",
    "    for topic in dp['topics']:\n",
    "        if topic in topics_to_check:\n",
    "            if class_topic is None:\n",
    "                class_topic = topic\n",
    "            else:\n",
    "                return {'class_topic': None}\n",
    "\n",
    "    return {'class_topic': class_topic}\n",
    "\n",
    "\n",
    "def class_topic_not_none(example):\n",
    "    return example['class_topic'] is not None\n",
    "\n",
    "\n",
    "df = df.map(classify_by_topic)\n",
    "df = df.filter(class_topic_not_none)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06087d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:21:57.036845Z",
     "start_time": "2024-05-28T13:21:57.034546Z"
    }
   },
   "source": [
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5edc3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:21:57.052294Z",
     "start_time": "2024-05-28T13:21:57.049710Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(df['class_topic'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d030ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:21:57.799905Z",
     "start_time": "2024-05-28T13:21:57.790355Z"
    }
   },
   "source": [
    "subset = {topic: [] for topic in topics_to_check}\n",
    "\n",
    "n_exampels = 3\n",
    "for dp in df.shuffle(2):\n",
    "    topic = dp['class_topic']\n",
    "\n",
    "    if len(subset[topic]) < n_exampels:\n",
    "        subset[topic].append(dp)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cf584fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:21:59.155823Z",
     "start_time": "2024-05-28T13:21:59.141739Z"
    }
   },
   "source": [
    "from datasets import Dataset\n",
    "df_s = Dataset.from_list([item for s in subset.values() for item in s]) "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "802a1aea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:21:59.730747Z",
     "start_time": "2024-05-28T13:21:59.728103Z"
    }
   },
   "source": [
    "for f in df_s['full_name']:\n",
    "    print(f'https://github.com/{f}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99e8a88-3cec-4e08-af26-6dec9e9116d0",
   "metadata": {},
   "source": [
    "df_s = df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1684c6f3-363e-4b7e-9222-f3e3418a4e0c",
   "metadata": {},
   "source": [
    "## Cloning repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0ba181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:22:01.056655Z",
     "start_time": "2024-05-28T13:22:01.054825Z"
    }
   },
   "source": [
    "repos_path = '/Users/Maria.Tigina/PycharmProjects/agents-eval-data/repos'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "264e8f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:22:01.369830Z",
     "start_time": "2024-05-28T13:22:01.365344Z"
    }
   },
   "source": [
    "from git import Repo\n",
    "import os\n",
    "\n",
    "for dp in df_s:\n",
    "    repo_path = f'{repos_path}/{\"__\".join(dp[\"full_name\"].split(\"/\"))}'\n",
    "    if os.path.exists(repo_path):\n",
    "        continue\n",
    "    Repo.clone_from(f'https://github.com/{dp[\"full_name\"]}.git',\n",
    "                    f'{repos_path}/{\"__\".join(dp[\"full_name\"].split(\"/\"))}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "01d5b4ce-8f43-4313-bf76-b2d33407ae1c",
   "metadata": {},
   "source": [
    "## Extract methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61b3339-22d8-4bb7-8e3f-e729193eb30f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:22:04.588261Z",
     "start_time": "2024-05-28T13:22:02.072684Z"
    }
   },
   "source": [
    "!pip install -U tree-sitter==0.21.3\n",
    "!pip install tree_sitter_languages"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e79868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:22:04.596190Z",
     "start_time": "2024-05-28T13:22:04.590264Z"
    }
   },
   "source": [
    "import fnmatch\n",
    "import os\n",
    "from tree_sitter_languages import get_language, get_parser\n",
    "\n",
    "language = get_language('python')\n",
    "parser = get_parser('python')\n",
    "\n",
    "def get_nodes_by_type(node, t: str):\n",
    "    t_nodes = []\n",
    "    if node.type == t:\n",
    "        t_nodes.append(node)\n",
    "    else:\n",
    "        for child in node.children:\n",
    "            t_nodes.extend(get_nodes_by_type(child, t))\n",
    "    return t_nodes\n",
    "\n",
    "\n",
    "def get_node_content(node, code) -> str:\n",
    "    start_byte = node.start_byte\n",
    "    end_byte = node.end_byte\n",
    "    return code[start_byte:end_byte].decode('utf-8')\n",
    "\n",
    "\n",
    "def extract_methods_from_code(code: str, language: str):\n",
    "    node_t_by_language = {\n",
    "        \"py\": 'function_definition',\n",
    "        \"java\": 'method_declaration'\n",
    "    }\n",
    "\n",
    "    t = node_t_by_language[language]\n",
    "    tree = parser.parse(code)\n",
    "    all_methods = get_nodes_by_type(tree.root_node, t)\n",
    "    method_contents = []\n",
    "    for method in all_methods:\n",
    "        method_content = get_node_content(method, code)\n",
    "        method_contents.append(method_content)\n",
    "\n",
    "    return method_contents\n",
    "\n",
    "\n",
    "def get_repo_files(directory: str, extension: str):\n",
    "    for root, dir, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if fnmatch.fnmatch(file, f\"*.{extension}\"):\n",
    "                yield os.path.join(root, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4bd85182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:22:19.415478Z",
     "start_time": "2024-05-28T13:22:04.597448Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "vect = {}\n",
    "for entity in ['files', 'methods', 'requirements']:\n",
    "    vect[entity] = {\n",
    "        'content': [],\n",
    "        'repo': [],\n",
    "        'path': [],\n",
    "        'vects': np.empty((0, 1024)),\n",
    "        'class_topic': []\n",
    "    }\n",
    "\n",
    "for dp in df_s:\n",
    "    repo = dp['full_name']\n",
    "    repo_path = os.path.join(repos_path, \"__\".join(dp[\"full_name\"].split(\"/\")))\n",
    "    requirements_path = os.path.join(repo_path, 'requirements.txt')\n",
    "    \n",
    "    for file_path in glob.glob(os.path.join(repo_path, '**/pyproject.toml'), recursive=True):\n",
    "        with open(file_path, 'r') as f:\n",
    "            file_content = f.read()\n",
    "            vect['requirements']['content'].append(file_content)\n",
    "            vect['requirements']['repo'].append(repo)\n",
    "            vect['requirements']['path'].append(file_path)\n",
    "            vect['requirements']['class_topic'].append(dp['class_topic'])\n",
    "\n",
    "    for file_path in glob.glob(os.path.join(repo_path, '**/requirements.txt'), recursive=True):\n",
    "        with open(file_path, 'r') as f:\n",
    "            file_content = f.read()\n",
    "            vect['requirements']['content'].append(file_content)\n",
    "            vect['requirements']['repo'].append(repo)\n",
    "            vect['requirements']['path'].append(file_path)\n",
    "            vect['requirements']['class_topic'].append(dp['class_topic'])\n",
    "            \n",
    "    for file_path in get_repo_files(repo_path, category):\n",
    "        with open(file_path, 'r') as f:\n",
    "            file_content = f.read()\n",
    "            vect['files']['content'].append(file_content)\n",
    "            vect['files']['repo'].append(repo)\n",
    "            vect['files']['path'].append(file_path)\n",
    "            vect['files']['class_topic'].append(dp['class_topic'])\n",
    "\n",
    "            source_code = bytes(file_content, \"utf8\")\n",
    "            methods = extract_methods_from_code(source_code, category)\n",
    "            for method in methods:\n",
    "                vect['methods']['content'].append(method)\n",
    "                vect['methods']['repo'].append(repo)\n",
    "                vect['methods']['path'].append(file_path)\n",
    "                vect['methods']['class_topic'].append(dp['class_topic'])\n",
    "\n",
    "model = SentenceTransformer('thenlper/gte-large')\n",
    "\n",
    "for entity in ['files', 'methods', 'requirements']:\n",
    "    vect[entity]['vects'] = model.encode(vect[entity]['content'])\n",
    "    print(vect[entity]['vects'].shape)\n",
    "    print(len(vect[entity]['content']))\n",
    "    print(len(vect[entity]['path']))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57c4ae3e-5a6b-4046-b4eb-222d761cac60",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "for entity in ['requirements']:\n",
    "    vect[entity]['content'] = [re.sub(r'==[0-9]+\\.[0-9]+\\.[0-9]+', '', content) for content in vect[entity]['content']]\n",
    "    vect[entity]['vects'] = vectorizer.fit_transform(vect[entity]['content']).toarray()\n",
    "    print(vect[entity]['vects'].shape)\n",
    "    print(len(vect[entity]['content']))\n",
    "    print(len(vect[entity]['path']))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3b7f629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:22:19.419278Z",
     "start_time": "2024-05-28T13:22:19.417054Z"
    }
   },
   "source": [
    "import collections\n",
    "for entity in ['files', 'methods', 'requirements']:\n",
    "    print(entity)\n",
    "    print(collections.Counter(vect[entity]['class_topic']))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ed8d8a3-f0df-4c20-8d7e-f48bba4797a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:22:57.294219Z",
     "start_time": "2024-05-28T13:22:56.859881Z"
    }
   },
   "source": [
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "def plot_tsne(vects, clusters, labels=None):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    methods_tsne = tsne.fit_transform(vects)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(\n",
    "        methods_tsne[:, 0],\n",
    "        methods_tsne[:, 1],\n",
    "        c=clusters,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "\n",
    "    if labels:\n",
    "        normalize = Normalize(vmin=min(labels.values()), vmax=max(labels.values()))\n",
    "        colormap = plt.cm.viridis\n",
    "\n",
    "        plt.figure(figsize=(2, 2))  # Adjust figure size for better visibility\n",
    "\n",
    "        for i, repo in enumerate(labels.keys()):\n",
    "            plt.plot([0, 1], [i, i], color=colormap(normalize(labels[repo])), linewidth=20)\n",
    "\n",
    "        plt.xticks([])  # Hide x-axis\n",
    "        plt.yticks(range(len(labels)), labels.keys())  # Show y-axis with labels\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1f90f67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:29:54.615131Z",
     "start_time": "2024-05-28T13:29:54.610540Z"
    }
   },
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "def classify(model, entity: str):\n",
    "    clusters = model.fit_predict(vect[entity]['vects'])\n",
    "    cluster_counts = collections.Counter(clusters)\n",
    "\n",
    "    large_clusters = {cluster: count for cluster, count in cluster_counts.items()}\n",
    "    print(large_clusters)\n",
    "\n",
    "    labels_mask = clusters != -1\n",
    "    print(f'Count noise: {np.count_nonzero(labels_mask == False)}')\n",
    "    repo = np.array(vect[entity]['repo'])\n",
    "    path = np.array(vect[entity]['path'])\n",
    "    content = np.array(vect[entity]['content'])\n",
    "    class_topic = np.array(vect[entity]['class_topic'])\n",
    "    \n",
    "    df_labels = pd.DataFrame({\n",
    "        'label': clusters[labels_mask],\n",
    "        'repo': repo[labels_mask],\n",
    "        'path': path[labels_mask], \n",
    "        'content': content[labels_mask], \n",
    "        'class_topic': class_topic[labels_mask]\n",
    "    })\n",
    "\n",
    "    # Clusters plot\n",
    "    plot_tsne(vect[entity]['vects'], clusters)\n",
    "    \n",
    "    for c in large_clusters.keys():\n",
    "        if c == -1:\n",
    "            continue\n",
    "        print(f\"Class {c}:\")\n",
    "        # print('repo:', dict(collections.Counter((df_labels[df_labels['label'] == c]['repo']))), sep='\\n')\n",
    "        # print('-------------------------------------------------------------------------------------------')\n",
    "        print('class_topic:', dict(collections.Counter(df_labels[df_labels['label'] == c]['class_topic'])), sep='\\n')\n",
    "        print('-------------------------------------------------------------------------------------------')\n",
    "        print('path:', *[p.split('repos/')[1] for p in set(df_labels[df_labels['label'] == c]['path'])], sep='\\n')\n",
    "\n",
    "        # for _, dp in df_labels[df_labels['label'] == c].iterrows():\n",
    "        #     print(dp['path'].split('repos')[1])\n",
    "        #     print(dp['content'])\n",
    "        #     print('-------------------------------------------------------------------------------------------')\n",
    "        print(\"===========================================================================================\\n\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2005364-8755-46ac-a5f6-be4e86423722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:29:56.680952Z",
     "start_time": "2024-05-28T13:29:55.087630Z"
    }
   },
   "source": [
    "# Actual plot\n",
    "entity = 'requirements'\n",
    "actual_labels = {r: i for i, r in enumerate(set(vect[entity]['repo']))}\n",
    "actual_clusters = np.array([actual_labels[r] for r in vect[entity]['repo']])\n",
    "plot_tsne(vect[entity]['vects'], actual_clusters, actual_labels)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1096e50a-4099-402c-83a7-867e31c4a160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:29:57.833606Z",
     "start_time": "2024-05-28T13:29:56.682282Z"
    }
   },
   "source": [
    "# Actual plot\n",
    "entity = 'requirements'\n",
    "actual_labels = {'fastapi': 1, 'flask': 0}\n",
    "actual_clusters = np.array([1 if c == 'fastapi' else 0 for c in vect[entity]['class_topic']])\n",
    "plot_tsne(vect[entity]['vects'], actual_clusters, actual_labels)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c294c449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:29:58.910450Z",
     "start_time": "2024-05-28T13:29:57.834521Z"
    }
   },
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# -1 stands for noise\n",
    "dbscan = DBSCAN(eps=0.08, min_samples=3)\n",
    "classify(dbscan, entity)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "524b90ba",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "classify(kmeans, entity)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5359f6c4-3b0d-477b-8e8a-18558085a88c",
   "metadata": {},
   "source": [
    "# top-k libs from req\n",
    "# fuzzy match node emb = concat content for subtree (for flask)\n",
    "# ====="
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93f8f4e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:23:45.034580Z",
     "start_time": "2024-05-28T13:23:43.326526Z"
    }
   },
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agg_model = AgglomerativeClustering(n_clusters=5)\n",
    "classify(agg_model, entity)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4687c698-9ee5-427c-a33a-cdee502d150a",
   "metadata": {},
   "source": [
    "!tree '/Users/Maria.Tigina/PycharmProjects/agents-eval-data/repos/abstractkitchen__flask-backbone'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9700e7b3-78de-44ff-b02b-3943faa64204",
   "metadata": {},
   "source": [
    "def parse_tree(root_path):\n",
    "    tree_dict = {}\n",
    "    start_path_len = len(root_path)\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        if dirpath.startswith(root_path):\n",
    "            parts = dirpath[start_path_len:].strip(os.sep).split(os.sep)\n",
    "            current_level = tree_dict\n",
    "            for part in parts:\n",
    "                if part not in current_level:\n",
    "                    current_level[part] = {}\n",
    "                current_level = current_level[part]\n",
    "\n",
    "            for dirname in dirnames:\n",
    "                if dirname not in current_level:\n",
    "                    current_level[dirname] = {}\n",
    "\n",
    "            for filename in filenames:\n",
    "                file_content = None\n",
    "                try:\n",
    "                    with open(os.path.join(dirpath, filename), 'r') as f:\n",
    "                        file_content = f.read()\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                current_level[filename] = file_content\n",
    "\n",
    "    return tree_dict"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "266bfff8-e813-4616-b048-2bd21cc3d355",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "parse_tree('/Users/Maria.Tigina/PycharmProjects/agents-eval-data/repos/abstractkitchen__flask-backbone')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e05d3dfd-7274-4a30-9698-9d4e2bb11643",
   "metadata": {},
   "source": [
    "for dp in df_s:\n",
    "    repo = dp['full_name']\n",
    "    repo_path = os.path.join(repos_path, \"__\".join(dp[\"full_name\"].split(\"/\")))\n",
    "    print(repo_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd4ae07-c79d-4ef7-8dac-5e84b0edfea9",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
